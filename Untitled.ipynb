{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'y.json'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-50-6f05aeb7bf93>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0;31m###### LOAD DATA ########\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 31\u001b[0;31m \u001b[0morgs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mjson\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloads\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'y.json'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     32\u001b[0m \u001b[0mutil\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mutil\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'prokaryotes/'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'y.json'"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk import bigrams\n",
    "from nltk import trigrams\n",
    "from nltk import FreqDist\n",
    "from nltk.util import ngrams\n",
    "from nltk.probability import LidstoneProbDist\n",
    "from collections import Counter\n",
    "from itertools import product\n",
    "from math import log\n",
    "from math import exp\n",
    "from Bio.Seq import Seq\n",
    "from Bio import SeqIO\n",
    "import os;\n",
    "import json\n",
    "from util import util\n",
    "\n",
    "###Perplexity method definition#\n",
    "def perplexity(test, model):\n",
    "    perp = 1\n",
    "    #iterate through all possible n-grams; won't work for n=1\n",
    "    for char in range(n, len(test)+1):\n",
    "        ngram = tuple(test[char-n:char])\n",
    "        try:\n",
    "            perp = perp + log(1/model.get(ngram))\n",
    "        except:\n",
    "            print(ngram)\n",
    "    perp = exp(perp/(len(test)+1-n)) \n",
    "    return perp\n",
    "\n",
    "###### LOAD DATA ########\n",
    "orgs = json.loads(open('y.json').read())\n",
    "util = util('prokaryotes/')\n",
    "        \n",
    "##Iterates through every FASTA file, parsing genome id (key) and sequence (value).\n",
    "orgs[\"eco\"][\"class\"]\n",
    "list(orgs.keys())[0]\n",
    "Escherichia = list()\n",
    "Treponema = list()\n",
    "for org in orgs.keys():\n",
    "    if(orgs[org][\"class\"] == \"Escherichia\"):\n",
    "        Escherichia.append(org);\n",
    "    if(orgs[org][\"class\"] == \"Treponema\"):\n",
    "        Treponema.append(org);\n",
    "print(Escherichia)\n",
    "print(Treponema)\n",
    "\n",
    "###### TRAIN N-gram Model ######\n",
    "n_array = [1,2,3]; #define the n for this n-gram\n",
    "#Laplacian smoothing for all combinations of n-gram; creates initial\n",
    "#frequency table with freq of var smooth given to every possible combination.\n",
    "smooth = 0.1\n",
    "vocabulary = \"ATCG\"\n",
    "smoothingVocab = ['A','T','C','G']\n",
    "train = util.get_single_org_genome('eco.fna')\n",
    "bgs_smooth = nltk.ngrams(\"\",1)\n",
    "ngram_features = nltk.FreqDist(bgs_smooth)\n",
    "\n",
    "for n in n_array:\n",
    "    #perms = [''.join(p) for p in product(vocabulary,repeat = n)]\n",
    "    bgs_smooth = nltk.ngrams(\"\",1)\n",
    "    fdist = nltk.FreqDist(bgs_smooth)\n",
    "    for i in range(0,n):\n",
    "        for p in product(vocabulary,repeat = n):\n",
    "            bgs_smooth = nltk.ngrams(p,n)\n",
    "            fdist += nltk.FreqDist(bgs_smooth)\n",
    "        for key,value in fdist.items(): \n",
    "            fdist[key] = value*smooth \n",
    "\n",
    "    #Calculate actual n-gram frequencies in training set and add to \n",
    "    #laplacian smoothing\n",
    "    bgs_train = nltk.ngrams(train,n)\n",
    "    fdist = nltk.FreqDist(bgs_train)\n",
    "    totalVal = sum(fdist.values())\n",
    "    for key in fdist.keys():\n",
    "        fdist[key] = fdist[key]/float(totalVal)\n",
    "    \n",
    "    \n",
    "#Convert n-gram frequencies to probabilities. |V| = 4^n is implicitly added to the denominator to account for laplacian smoothing,\n",
    "#since fdist.values already have 1 added to each |V|.\n",
    "\n",
    "\n",
    "sortedKeys = sorted(fdist.keys())\n",
    "sortedFeatures = sorted(fdist.keys())\n",
    "for i in range(0,len(sortedFeatures)):\n",
    "    sortedFeatures[i] = fdist[sortedKeys[i]]\n",
    "print(sortedFeatures)\n",
    "\n",
    "\n",
    "##### CALCULATE TEST SEQUENCE PERPLEXITY #####\n",
    "#test = util.get_single_org_genome(Escherichia[1]+'.fna')\n",
    "#file = open(\"newfile.txt\", \"w\")\n",
    "#file.write(test)\n",
    "#print(len(Treponema[1]))\n",
    "#perp = perplexity(test,fdist)\n",
    "#print(perp)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
