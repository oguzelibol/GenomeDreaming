{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1830138\n",
      "['slg', 'saum', 'sxy', 'sab', 'saub', 'sao', 'scap', 'sax', 'suh', 'sauk', 'sauj', 'sad', 'shh', 'sam', 'sux', 'sca', 'sue', 'sep', 'saj', 'sepp', 'sdt', 'saus', 'saui', 'sauq', 'ser', 'sauz', 'ssp', 'saua', 'sauu', 'sud', 'sar', 'saw', 'sagq', 'sauf', 'sha', 'swa', 'sut', 'suk', 'sauv', 'saa', 'sas', 'sauy', 'shu', 'saud', 'seqo', 'saux', 'suj', 'spas', 'saug', 'ssch', 'sac', 'ssd', 'sxl', 'sauw', 'suq', 'sauc', 'sxo', 'sln', 'suv', 'seps', 'saun', 'suc', 'suw', 'sau', 'suf', 'sav', 'sae', 'saut', 'sug', 'suu', 'ssif', 'saue', 'saur', 'suz', 'sah', 'suy']\n",
      "2864125\n",
      "('A',)\n",
      "('G',)\n",
      "('C',)\n",
      "('T',)\n",
      "3.7259497549593728\n",
      "2836901\n",
      "('G',)\n",
      "('C',)\n",
      "('T',)\n",
      "('A',)\n",
      "3.764460151256763\n",
      "2742531\n",
      "('G',)\n",
      "('C',)\n",
      "('T',)\n",
      "('A',)\n",
      "3.7649937980409764\n",
      "2782313\n",
      "('G',)\n",
      "('C',)\n",
      "('T',)\n",
      "('A',)\n",
      "3.7693126158048558\n",
      "4979619\n",
      "('G',)\n",
      "('C',)\n",
      "('T',)\n",
      "('A',)\n",
      "3.999682178013163\n",
      "4701875\n",
      "('G',)\n",
      "('C',)\n",
      "('T',)\n",
      "('A',)\n",
      "3.9999231562051056\n",
      "5263980\n",
      "('G',)\n",
      "('C',)\n",
      "('T',)\n",
      "('A',)\n",
      "3.999822946927931\n",
      "5131397\n",
      "('G',)\n",
      "('C',)\n",
      "('T',)\n",
      "('A',)\n",
      "3.999720993565193\n",
      "[('A',), ('C',), ('G',), ('T',)]\n",
      "[[0.3344590317472062, 0.16363981580132697, 0.16291712466411568, 0.33898402778735115], [0.3327475886190475, 0.16586692085949833, 0.16180438981770745, 0.3395811007037467], [0.3356607330001764, 0.16349497402290453, 0.1642924124770276, 0.33655188049989143], [0.33541875620481865, 0.16338817187165183, 0.16601620076300536, 0.3351768711605242], [0.24739985148262536, 0.25364249725591476, 0.2525737408766622, 0.24638391038479768], [0.2512523194468318, 0.24814058237272726, 0.2488211618708569, 0.25178593630958407], [0.24819414221223163, 0.2522614065964227, 0.252384507358728, 0.2471599438326176], [0.24769297735544707, 0.25301375021158956, 0.25282569227633783, 0.24646758015662557]]\n",
      "[0, 0, 0, 0, 1, 1, 1, 1]\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk import bigrams\n",
    "from nltk import trigrams\n",
    "from nltk import FreqDist\n",
    "from nltk.util import ngrams\n",
    "from nltk.probability import LidstoneProbDist\n",
    "from collections import Counter\n",
    "from itertools import product\n",
    "from math import log\n",
    "from math import exp\n",
    "from Bio.Seq import Seq\n",
    "from Bio import SeqIO\n",
    "import os;\n",
    "import json\n",
    "from util import util\n",
    "import numpy as np\n",
    "from sklearn import preprocessing,svm\n",
    "\n",
    "\n",
    "###### LOAD DATA ########\n",
    "orgs = json.loads(open('y.json').read())\n",
    "util = util('/Users/Akshay/Google Drive/prokaryotes/')\n",
    "        \n",
    "##Iterates through every FASTA file, parsing genome id (key) and sequence (value).\n",
    "orgs[\"eco\"][\"class\"]\n",
    "list(orgs.keys())[0]\n",
    "Escherichia = list()\n",
    "Staphylococcus = list()\n",
    "for org in orgs.keys():\n",
    "    if(orgs[org][\"class\"] == \"Escherichia\"):\n",
    "        Escherichia.append(org);\n",
    "    if(orgs[org][\"class\"] == \"Staphylococcus\"):\n",
    "        Staphylococcus.append(org);\n",
    "print(Staphylococcus)\n",
    "classes = list()\n",
    "classes.append(Staphylococcus)\n",
    "classes.append(Escherichia);\n",
    "\n",
    "\n",
    "#Perplexity calculation. Remembe I need to add +V to bottom probability.\n",
    "#Used log probabilities, so log perplexity calculation since risk of underflow with lots of probabilities\n",
    "def perplexity(test, model):\n",
    "    perp = 0\n",
    "    for char in range(n, len(test)+1):\n",
    "        ngram = tuple(test[char-n:char])\n",
    "        try:\n",
    "            perp = perp + log(1/model.get(ngram))\n",
    "        except:\n",
    "            perp\n",
    "    perp = exp(perp/(len(test)+1-n)) \n",
    "    return perp\n",
    "\n",
    "\n",
    "def singleGram(train,test,n):\n",
    "    #Laplacian smoothing for all combinations of n-gram; creates initial\n",
    "    #frequency table with freq of var smooth given to every possible combination.\n",
    "    smooth = 0.1\n",
    "    vocabulary = \"ATCG\"\n",
    "    smoothingVocab = ['A','T','C','G']\n",
    "    #perms = [''.join(p) for p in product(vocabulary,repeat = n)]\n",
    "    bgs_smooth = nltk.ngrams(\"\",1)\n",
    "    fdist = nltk.FreqDist(bgs_smooth)\n",
    "    for p in product(vocabulary,repeat = n):\n",
    "        bgs_smooth = nltk.ngrams(p,n)\n",
    "        fdist += nltk.FreqDist(bgs_smooth)\n",
    "    for key,value in fdist.items(): \n",
    "        fdist[key] = value*smooth\n",
    "\n",
    "    #Calculate actual n-gram frequencies in training set and add to \n",
    "    #laplacian smoothing\n",
    "    bgs_train = nltk.ngrams(train,n)\n",
    "    fdistTemp = nltk.FreqDist(bgs_train)\n",
    "    for key in fdistTemp.keys(): #This for loop is only here because some genomes contain non-ATCG characters\n",
    "        if key in fdist.keys():\n",
    "            fdist[key] += fdistTemp[key];\n",
    "            \n",
    "    #Convert n-gram frequencies to probabilities. |V| = 4^n is implicitly added to the denominator to account for laplacian smoothing,\n",
    "    #since fdist.values already have 1 added to each |V|.\n",
    "    totalVal = sum(fdist.values())\n",
    "    for key in fdist.keys():\n",
    "        fdist[key] = fdist[key]/float(totalVal)\n",
    "    #fdist.values()\n",
    "    \n",
    "    ##### CALCULATE TEST SEQUENCE PERPLEXITY #####\n",
    "    perp = perplexity(test,fdist)\n",
    "    print(perp)\n",
    "    \n",
    "    return fdist\n",
    "\n",
    "###### TRAIN N-gram Model ######\n",
    "n_max = 2; #define the max n (model will be built w/ n-gram from 1 to n_max)\n",
    "X = list();\n",
    "X_label = list()\n",
    "classCount = -1\n",
    "y = list();\n",
    "for cl in iter(classes):\n",
    "    classCount += 1\n",
    "    for org in iter(cl):\n",
    "        train = util.get_clean_single_org_genome('clean_'+org + '.fna')\n",
    "        test = util.get_clean_single_org_genome('clean_' + org+ '.fna')\n",
    "        print(len(test))\n",
    "        bgs_smooth = nltk.ngrams(\"\",1)\n",
    "        fdist_tot = nltk.FreqDist(bgs_smooth)\n",
    "        for n in range(1,n_max+1):\n",
    "            fdist_tot += singleGram(train,test,n)\n",
    "        sortedKeys = sorted(fdist_tot.keys())\n",
    "        sortedFeatures = sorted(fdist_tot.keys())\n",
    "        for i in range(0,len(sortedFeatures)):\n",
    "            sortedFeatures[i] = fdist_tot[sortedKeys[i]]\n",
    "        X.append(sortedFeatures)\n",
    "        y.append(classCount)\n",
    "## TEST ###\n",
    "print(X)\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 1.  1.  1.]\n",
      "1.0\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)\n",
    "clf = svm.SVC()\n",
    "scores = cross_val_score(clf, X, y, cv=3)\n",
    "print(scores)\n",
    "\n",
    "clf = svm.SVC(kernel='linear', C=1).fit(X_train, y_train)\n",
    "print(clf.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Automatically created module for IPython interactive environment\n",
      "# Tuning hyper-parameters for precision\n",
      "\n",
      "Best parameters set found on development set:\n",
      "\n",
      "{'C': 10, 'gamma': 0.001, 'kernel': 'rbf'}\n",
      "\n",
      "Grid scores on development set:\n",
      "\n",
      "0.991 (+/-0.008) for {'C': 1, 'gamma': 0.001, 'kernel': 'rbf'}\n",
      "0.971 (+/-0.010) for {'C': 1, 'gamma': 0.0001, 'kernel': 'rbf'}\n",
      "0.992 (+/-0.005) for {'C': 10, 'gamma': 0.001, 'kernel': 'rbf'}\n",
      "0.988 (+/-0.012) for {'C': 10, 'gamma': 0.0001, 'kernel': 'rbf'}\n",
      "0.992 (+/-0.005) for {'C': 100, 'gamma': 0.001, 'kernel': 'rbf'}\n",
      "0.988 (+/-0.014) for {'C': 100, 'gamma': 0.0001, 'kernel': 'rbf'}\n",
      "0.992 (+/-0.005) for {'C': 1000, 'gamma': 0.001, 'kernel': 'rbf'}\n",
      "0.988 (+/-0.014) for {'C': 1000, 'gamma': 0.0001, 'kernel': 'rbf'}\n",
      "0.983 (+/-0.017) for {'C': 1, 'kernel': 'linear'}\n",
      "0.983 (+/-0.017) for {'C': 10, 'kernel': 'linear'}\n",
      "0.983 (+/-0.017) for {'C': 100, 'kernel': 'linear'}\n",
      "0.983 (+/-0.017) for {'C': 1000, 'kernel': 'linear'}\n",
      "\n",
      "Detailed classification report:\n",
      "\n",
      "The model is trained on the full development set.\n",
      "The scores are computed on the full evaluation set.\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      1.00      1.00        37\n",
      "          1       0.98      1.00      0.99        43\n",
      "          2       1.00      1.00      1.00        44\n",
      "          3       1.00      1.00      1.00        45\n",
      "          4       1.00      1.00      1.00        38\n",
      "          5       0.98      0.98      0.98        48\n",
      "          6       1.00      1.00      1.00        52\n",
      "          7       1.00      1.00      1.00        48\n",
      "          8       1.00      0.98      0.99        48\n",
      "          9       0.98      0.98      0.98        47\n",
      "\n",
      "avg / total       0.99      0.99      0.99       450\n",
      "\n",
      "\n",
      "# Tuning hyper-parameters for recall\n",
      "\n",
      "Best parameters set found on development set:\n",
      "\n",
      "{'C': 10, 'gamma': 0.001, 'kernel': 'rbf'}\n",
      "\n",
      "Grid scores on development set:\n",
      "\n",
      "0.991 (+/-0.008) for {'C': 1, 'gamma': 0.001, 'kernel': 'rbf'}\n",
      "0.970 (+/-0.009) for {'C': 1, 'gamma': 0.0001, 'kernel': 'rbf'}\n",
      "0.992 (+/-0.006) for {'C': 10, 'gamma': 0.001, 'kernel': 'rbf'}\n",
      "0.987 (+/-0.012) for {'C': 10, 'gamma': 0.0001, 'kernel': 'rbf'}\n",
      "0.992 (+/-0.006) for {'C': 100, 'gamma': 0.001, 'kernel': 'rbf'}\n",
      "0.987 (+/-0.015) for {'C': 100, 'gamma': 0.0001, 'kernel': 'rbf'}\n",
      "0.992 (+/-0.006) for {'C': 1000, 'gamma': 0.001, 'kernel': 'rbf'}\n",
      "0.987 (+/-0.015) for {'C': 1000, 'gamma': 0.0001, 'kernel': 'rbf'}\n",
      "0.982 (+/-0.018) for {'C': 1, 'kernel': 'linear'}\n",
      "0.982 (+/-0.018) for {'C': 10, 'kernel': 'linear'}\n",
      "0.982 (+/-0.018) for {'C': 100, 'kernel': 'linear'}\n",
      "0.982 (+/-0.018) for {'C': 1000, 'kernel': 'linear'}\n",
      "\n",
      "Detailed classification report:\n",
      "\n",
      "The model is trained on the full development set.\n",
      "The scores are computed on the full evaluation set.\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      1.00      1.00        37\n",
      "          1       0.98      1.00      0.99        43\n",
      "          2       1.00      1.00      1.00        44\n",
      "          3       1.00      1.00      1.00        45\n",
      "          4       1.00      1.00      1.00        38\n",
      "          5       0.98      0.98      0.98        48\n",
      "          6       1.00      1.00      1.00        52\n",
      "          7       1.00      1.00      1.00        48\n",
      "          8       1.00      0.98      0.99        48\n",
      "          9       0.98      0.98      0.98        47\n",
      "\n",
      "avg / total       0.99      0.99      0.99       450\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "\n",
    "from sklearn import datasets\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "print(__doc__)\n",
    "\n",
    "# Loading the Digits dataset\n",
    "digits = datasets.load_digits()\n",
    "\n",
    "# To apply an classifier on this data, we need to flatten the image, to\n",
    "# turn the data in a (samples, feature) matrix:\n",
    "n_samples = len(digits.images)\n",
    "X = digits.images.reshape((n_samples, -1))\n",
    "y = digits.target\n",
    "\n",
    "# Split the dataset in two equal parts\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.25, random_state=0)\n",
    "\n",
    "# Set the parameters by cross-validation\n",
    "tuned_parameters = [{'kernel': ['rbf'], 'gamma': [1e-3, 1e-4],\n",
    "                     'C': [1, 10, 100, 1000]},\n",
    "                    {'kernel': ['linear'], 'C': [1, 10, 100, 1000]}]\n",
    "\n",
    "scores = ['precision', 'recall']\n",
    "\n",
    "for score in scores:\n",
    "    print(\"# Tuning hyper-parameters for %s\" % score)\n",
    "    print()\n",
    "\n",
    "    clf = GridSearchCV(SVC(C=1), tuned_parameters, cv=5,\n",
    "                       scoring='%s_macro' % score)\n",
    "    clf.fit(X_train, y_train)\n",
    "\n",
    "    print(\"Best parameters set found on development set:\")\n",
    "    print()\n",
    "    print(clf.best_params_)\n",
    "    print()\n",
    "    print(\"Grid scores on development set:\")\n",
    "    print()\n",
    "    means = clf.cv_results_['mean_test_score']\n",
    "    stds = clf.cv_results_['std_test_score']\n",
    "    for mean, std, params in zip(means, stds, clf.cv_results_['params']):\n",
    "        print(\"%0.3f (+/-%0.03f) for %r\"\n",
    "              % (mean, std * 2, params))\n",
    "    print()\n",
    "\n",
    "    print(\"Detailed classification report:\")\n",
    "    print()\n",
    "    print(\"The model is trained on the full development set.\")\n",
    "    print(\"The scores are computed on the full evaluation set.\")\n",
    "    print()\n",
    "    y_true, y_pred = y_test, clf.predict(X_test)\n",
    "    print(classification_report(y_true, y_pred))\n",
    "    print()\n",
    "\n",
    "# Note the problem is too easy: the hyperparameter plateau is too flat and the\n",
    "# output model is the same for precision and recall with ties in quality."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
