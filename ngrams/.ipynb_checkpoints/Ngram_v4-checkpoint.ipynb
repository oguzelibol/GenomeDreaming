{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['suy', 'sah', 'saub', 'ssif', 'saug', 'suf', 'sauz', 'sxo', 'sca', 'saw', 'saux', 'shh', 'sauu', 'sauk', 'saus', 'sax', 'suv', 'seps', 'sepp', 'saut', 'saum', 'sagq', 'suj', 'suk', 'sam', 'suq', 'suc', 'saun', 'saa', 'slg', 'sas', 'suu', 'sau', 'sep', 'sux', 'sauj', 'sauq', 'seqo', 'saud', 'sauv', 'sha', 'ser', 'saj', 'sav', 'scap', 'sab', 'sad', 'swa', 'spas', 'sut', 'sxl', 'suz', 'sauc', 'sac', 'sdt', 'saui', 'ssd', 'sae', 'sug', 'sue', 'sud', 'sln', 'saur', 'sar', 'sauw', 'sxy', 'suh', 'ssp', 'suw', 'ssch', 'saue', 'sauy', 'sao', 'shu', 'saua', 'sauf']\n",
      "suy\n",
      "3\n",
      "sah\n",
      "3\n",
      "saub\n",
      "4\n",
      "ssif\n",
      "4\n",
      "saug\n",
      "4\n",
      "suf\n",
      "3\n",
      "sauz\n",
      "4\n",
      "sxo\n",
      "3\n",
      "sca\n",
      "3\n",
      "saw\n",
      "3\n",
      "saux\n",
      "4\n",
      "shh\n",
      "3\n",
      "sauu\n",
      "4\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk import bigrams\n",
    "from nltk import trigrams\n",
    "from nltk import FreqDist\n",
    "from nltk.util import ngrams\n",
    "from nltk.probability import LidstoneProbDist\n",
    "from collections import Counter\n",
    "from itertools import product\n",
    "from math import log\n",
    "from math import exp\n",
    "from Bio.Seq import Seq\n",
    "from Bio import SeqIO\n",
    "import os;\n",
    "import json\n",
    "from util import util\n",
    "import numpy as np\n",
    "from sklearn import preprocessing,cross_validation,svm\n",
    "\n",
    "###### LOAD DATA ########\n",
    "dataPath = '/Users/Akshay/Dropbox/code/GenomeDreaming/data/'\n",
    "\n",
    "##Iterates through every FASTA file, parsing genome id (key) and sequence (value).\n",
    "genomes = []\n",
    "for fastaFile in os.listdir(dataPath):\n",
    "    if \"fna\" in fastaFile: #ensures only fasta files being read\n",
    "        handle = open(dataPath + fastaFile, \"r\")\n",
    "        genomes.append(list(SeqIO.parse(handle, \"fasta\")))\n",
    "        handle.close()\n",
    "len(genomes[1][0].seq)\n",
    "\n",
    "###### LOAD DATA ########\n",
    "orgs = json.loads(open('y.json').read())\n",
    "util = util('prokaryotes/')\n",
    "        \n",
    "##Iterates through every FASTA file, parsing genome id (key) and sequence (value).\n",
    "orgs[\"eco\"][\"class\"]\n",
    "list(orgs.keys())[0]\n",
    "Escherichia = list()\n",
    "Staphylococcus = list()\n",
    "for org in orgs.keys():\n",
    "    if(orgs[org][\"class\"] == \"Escherichia\"):\n",
    "        Escherichia.append(org);\n",
    "    if(orgs[org][\"class\"] == \"Staphylococcus\"):\n",
    "        Staphylococcus.append(org);\n",
    "print(Staphylococcus)\n",
    "classes = list()\n",
    "classes.append(Staphylococcus)\n",
    "classes.append(Escherichia);\n",
    "for cl in iter(classes):\n",
    "    classCount += 1\n",
    "    for org in iter(cl):\n",
    "        train = util.get_single_org_genome('eco.fna')\n",
    "        test = util.get_single_org_genome('eco.fna')\n",
    "        print(org)\n",
    "        print(len(util.get_single_org_genome(org+'.fna')))\n",
    "\n",
    "\n",
    "\n",
    "#Perplexity calculation. Remembe I need to add +V to bottom probability.\n",
    "#Used log probabilities, so log perplexity calculation since risk of underflow with lots of probabilities\n",
    "def perplexity(test, model):\n",
    "    perp = 1\n",
    "    #iterate through all possible n-grams; won't work for n=1\n",
    "    for char in range(n, len(test)+1):\n",
    "        ngram = tuple(test[char-n:char])\n",
    "        try:\n",
    "            perp = perp + log(1/model.get(ngram))\n",
    "        except:\n",
    "            perp\n",
    "    perp = exp(perp/(len(test)+1-n)) \n",
    "    return perp\n",
    "\n",
    "\n",
    "###### TRAIN N-gram Model ######\n",
    "n = 1; #define the n for this n-gram\n",
    "\n",
    "def singleGram(train,test,n):\n",
    "    #Laplacian smoothing for all combinations of n-gram; creates initial\n",
    "    #frequency table with freq of var smooth given to every possible combination.\n",
    "    smooth = 0.1\n",
    "    vocabulary = \"ATCG\"\n",
    "    smoothingVocab = ['A','T','C','G']\n",
    "    #perms = [''.join(p) for p in product(vocabulary,repeat = n)]\n",
    "    bgs_smooth = nltk.ngrams(\"\",1)\n",
    "    fdist = nltk.FreqDist(bgs_smooth)\n",
    "    for p in product(vocabulary,repeat = n):\n",
    "        bgs_smooth = nltk.ngrams(p,n)\n",
    "        fdist += nltk.FreqDist(bgs_smooth)\n",
    "    for key,value in fdist.items(): \n",
    "        fdist[key] = value*smooth\n",
    "\n",
    "    #Calculate actual n-gram frequencies in training set and add to \n",
    "    #laplacian smoothing\n",
    "    bgs_train = nltk.ngrams(train,n)\n",
    "    fdist += nltk.FreqDist(bgs_train)\n",
    "\n",
    "    #Convert n-gram frequencies to probabilities. |V| = 4^n is implicitly added to the denominator to account for laplacian smoothing,\n",
    "    #since fdist.values already have 1 added to each |V|.\n",
    "    totalVal = sum(fdist.values())\n",
    "    for key in fdist.keys():\n",
    "        fdist[key] = fdist[key]/float(totalVal)\n",
    "    #fdist.values()\n",
    "    return fdist\n",
    "\n",
    "##### CALCULATE TEST SEQUENCE PERPLEXITY #####\n",
    "train = util.get_single_org_genome(Staphylococcus[2] + '.fna')\n",
    "test =  util.get_single_org_genome(Staphylococcus[2] + '.fna')\n",
    "\n",
    "for cl in iter(classes):\n",
    "    classCount += 1\n",
    "    for org in iter(cl):\n",
    "        train = util.get_single_org_genome('eco.fna')\n",
    "        test = util.get_single_org_genome('eco.fna')\n",
    "        print(org)\n",
    "        print(len(org))\n",
    "        fdist = singleGram(train,test,n)\n",
    "        print(perplexity(test,fdist))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "clf = svm.SVC(decision_function_shape='ovo')\n",
    "clf.fit(X,y)\n",
    "accuracy = clf.score(X,y)\n",
    "print(accuracy)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
