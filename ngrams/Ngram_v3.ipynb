{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['slg', 'saue', 'suy', 'sauz', 'suc', 'suw', 'sauu', 'saug', 'saun', 'sha', 'sxy', 'sxl', 'saud', 'sab', 'sdt', 'suk', 'sud', 'sauf', 'sue', 'sca', 'seqo', 'suu', 'sut', 'shh', 'sas', 'sauy', 'sep', 'shu', 'seps', 'swa', 'saur', 'ssp', 'ssd', 'sepp', 'sam', 'sar', 'sauq', 'sug', 'sauv', 'saub', 'sah', 'sauc', 'sln', 'suz', 'saut', 'saw', 'suv', 'saux', 'sae', 'saua', 'sad', 'saui', 'sagq', 'scap', 'sauk', 'sac', 'sauw', 'suf', 'spas', 'ssch', 'suj', 'suq', 'sux', 'saum', 'suh', 'saa', 'sao', 'saus', 'sxo', 'ser', 'sav', 'sax', 'ssif', 'saj', 'sau', 'sauj']\n",
      "2658366\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-70c50f595a3d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    103\u001b[0m         \u001b[0mfdist_tot\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnltk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mFreqDist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbgs_smooth\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    104\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mn\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mn_max\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 105\u001b[0;31m             \u001b[0mfdist_tot\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0msingleGram\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtest\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    106\u001b[0m         \u001b[0msortedKeys\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msorted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfdist_tot\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    107\u001b[0m         \u001b[0msortedFeatures\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msorted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfdist_tot\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-1-70c50f595a3d>\u001b[0m in \u001b[0;36msingleGram\u001b[0;34m(train, test, n)\u001b[0m\n\u001b[1;32m     83\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     84\u001b[0m     \u001b[0;31m##### CALCULATE TEST SEQUENCE PERPLEXITY #####\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 85\u001b[0;31m     \u001b[0mperp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mperplexity\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mfdist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     86\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mperp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     87\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-1-70c50f595a3d>\u001b[0m in \u001b[0;36mperplexity\u001b[0;34m(test, model)\u001b[0m\n\u001b[1;32m     43\u001b[0m     \u001b[0mperp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mchar\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 45\u001b[0;31m         \u001b[0mngram\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mchar\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mchar\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     46\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m             \u001b[0mperp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mperp\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mlog\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mngram\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk import bigrams\n",
    "from nltk import trigrams\n",
    "from nltk import FreqDist\n",
    "from nltk.util import ngrams\n",
    "from nltk.probability import LidstoneProbDist\n",
    "from collections import Counter\n",
    "from itertools import product\n",
    "from math import log\n",
    "from math import exp\n",
    "from Bio.Seq import Seq\n",
    "from Bio import SeqIO\n",
    "import os;\n",
    "import json\n",
    "from util import util\n",
    "import numpy as np\n",
    "from sklearn import preprocessing,svm\n",
    "\n",
    "\n",
    "###### LOAD DATA ########\n",
    "orgs = json.loads(open('y.json').read())\n",
    "util = util('/Users/Akshay/Google Drive/prokaryotes/')\n",
    "        \n",
    "##Iterates through every FASTA file, parsing genome id (key) and sequence (value).\n",
    "orgs[\"eco\"][\"class\"]\n",
    "list(orgs.keys())[0]\n",
    "Escherichia = list()\n",
    "Staphylococcus = list()\n",
    "for org in orgs.keys():\n",
    "    if(orgs[org][\"class\"] == \"Escherichia\"):\n",
    "        Escherichia.append(org);\n",
    "    if(orgs[org][\"class\"] == \"Staphylococcus\"):\n",
    "        Staphylococcus.append(org);\n",
    "print(Staphylococcus)\n",
    "classes = list()\n",
    "classes.append(Staphylococcus)\n",
    "classes.append(Escherichia);\n",
    "\n",
    "\n",
    "#Perplexity calculation. Remembe I need to add +V to bottom probability.\n",
    "#Used log probabilities, so log perplexity calculation since risk of underflow with lots of probabilities\n",
    "def perplexity(test, model):\n",
    "    perp = 0\n",
    "    for char in range(n, len(test)+1):\n",
    "        ngram = tuple(test[char-n:char])\n",
    "        try:\n",
    "            perp = perp + log(1/model.get(ngram))\n",
    "        except:\n",
    "            perp\n",
    "    perp = exp(perp/(len(test)+1-n)) \n",
    "    return perp\n",
    "\n",
    "\n",
    "def singleGram(train,test,n):\n",
    "    #Laplacian smoothing for all combinations of n-gram; creates initial\n",
    "    #frequency table with freq of var smooth given to every possible combination.\n",
    "    smooth = 0.1\n",
    "    vocabulary = \"ATCG\"\n",
    "    smoothingVocab = ['A','T','C','G']\n",
    "    #perms = [''.join(p) for p in product(vocabulary,repeat = n)]\n",
    "    bgs_smooth = nltk.ngrams(\"\",1)\n",
    "    fdist = nltk.FreqDist(bgs_smooth)\n",
    "    for p in product(vocabulary,repeat = n):\n",
    "        bgs_smooth = nltk.ngrams(p,n)\n",
    "        fdist += nltk.FreqDist(bgs_smooth)\n",
    "    for key,value in fdist.items(): \n",
    "        fdist[key] = value*smooth\n",
    "\n",
    "    #Calculate actual n-gram frequencies in training set and add to \n",
    "    #laplacian smoothing\n",
    "    bgs_train = nltk.ngrams(train,n)\n",
    "    fdistTemp = nltk.FreqDist(bgs_train)\n",
    "    for key in fdistTemp.keys(): #This for loop is only here because some genomes contain non-ATCG characters\n",
    "        if key in fdist.keys():\n",
    "            fdist[key] += fdistTemp[key];\n",
    "            \n",
    "    #Convert n-gram frequencies to probabilities. |V| = 4^n is implicitly added to the denominator to account for laplacian smoothing,\n",
    "    #since fdist.values already have 1 added to each |V|.\n",
    "    totalVal = sum(fdist.values())\n",
    "    for key in fdist.keys():\n",
    "        fdist[key] = fdist[key]/float(totalVal)\n",
    "    #fdist.values()\n",
    "    \n",
    "    ##### CALCULATE TEST SEQUENCE PERPLEXITY #####\n",
    "    perp = perplexity(test,fdist)\n",
    "    print(perp)\n",
    "    \n",
    "    return fdist\n",
    "\n",
    "###### TRAIN N-gram Model ######\n",
    "n_max = 5; #define the max n (model will be built w/ n-gram from 1 to n_max)\n",
    "X = list();\n",
    "X_label = list()\n",
    "classCount = -1\n",
    "y = list();\n",
    "for cl in iter(classes):\n",
    "    classCount += 1\n",
    "    for org in iter(cl):\n",
    "        train = util.get_clean_single_org_genome('clean_'+org + '.fna')\n",
    "        test = util.get_clean_single_org_genome('clean_' + org+ '.fna')\n",
    "        print(len(test))\n",
    "        bgs_smooth = nltk.ngrams(\"\",1)\n",
    "        fdist_tot = nltk.FreqDist(bgs_smooth)\n",
    "        for n in range(1,n_max+1):\n",
    "            fdist_tot += singleGram(train,test,n)\n",
    "        sortedKeys = sorted(fdist_tot.keys())\n",
    "        sortedFeatures = sorted(fdist_tot.keys())\n",
    "        for i in range(0,len(sortedFeatures)):\n",
    "            sortedFeatures[i] = fdist_tot[sortedKeys[i]]\n",
    "        X.append(sortedFeatures)\n",
    "        y.append(classCount)\n",
    "## TEST ###\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-4-3a2815a8ce0b>, line 6)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-4-3a2815a8ce0b>\"\u001b[0;36m, line \u001b[0;32m6\u001b[0m\n\u001b[0;31m    X = [ -6.57469975  -8.92463708  -9.0564147   10.7978779   -8.83023071\u001b[0m\n\u001b[0m                                                          ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "Y = [2, 2, 2, 1, 2, 2, 3, 2, 1, 1, 3, 1, 1, 1, 1, 2, 3, 2, 1, 3, 3, 2, 2, 3, 2, 1, 2, 2, 2, 1, 3, 1, 1, 1, 3, 1, 2, 1, 2, 2, 2, 3, 2, 3, 2, 1, 3, 1, 2, 3, 3, 3, 1, 1, 3, 1, 1, 3, 1, 2, 1, 1, 1, 2, 1, 3, 3, 2, 3, 2, 1, 1, 2, 2, 2, 1, 3, 1, 1, 2, 1, 3, 3, 1, 3, 2, 2, 1, 3, 3, 1, 2, 3, 1, 2, 2, 1, 2, 1, 2, 2, 2, 3, 3, 2, 2, 3, 3, 2, 2, 2, 3, 1, 2, 1, 1, 2, 1, 2, 2, 1, 3, 2, 3, 3, 3, 1, 3, 3, 3, 3, 3, 3, 3, 2, 1, 1, 1, 3, 3, 3, 2, 1, 1, 3, 1, 2, 3, 1, 3, 2, 2, 1, 3, 2, 3, 1, 2, 3, 2, 2, 1, 1, 2, 1, 1, 2, 1, 1, 2, 1, 1, 2, 1, 1, 2, 2, 1, 1, 1, 3, 2, 3, 2, 1, 3, 2, 2, 3, 3, 3, 1, 1, 2, 2, 3, 3, 1, 2, 2, 2, 1, 1, 1, 3, 1, 1, 1, 3, 1, 1, 2, 1, 3, 3, 3, 2, 1, 1, 3, 1, 1, 2, 2, 3, 3]\n",
    "X = \n",
    "X_train, X_holdout, y_train, y_holdout = train_test_split(X, y, test_size=0.3, random_state=3)\n",
    "clf = svm.SVC()\n",
    "scores = cross_val_score(clf, X_train, y_train, cv=5)\n",
    "print(scores)\n",
    "\n",
    "clf = svm.SVC(kernel='linear', C=1).fit(X_train, y_train)\n",
    "print(clf.score(X_holdout, y_holdout))\n",
    "#Note, kernel='linear', C=1 and kernel = 'rbf', C=1000,gamma=0.001 perform as well with 100% accuracy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "y = pickle.load( open( \"y_5gram.p\", \"rb\" ) )\n",
    "X = pickle.load( open( \"X_5gram.p\", \"rb\" ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "\n",
    "from sklearn import datasets\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "print(__doc__)\n",
    "\n",
    "\n",
    "X_trainGrid, X_testGrid, y_trainGrid, y_testGrid = train_test_split(\n",
    "    X_train, y_train, test_size=0.2, random_state=0)\n",
    "\n",
    "# Set the parameters by cross-validation\n",
    "tuned_parameters = [{'kernel': ['rbf'], 'gamma': [1e-3, 1e-4],\n",
    "                     'C': [1, 10, 100, 1000]},\n",
    "                    {'kernel': ['linear'], 'C': [1, 10, 100, 1000]}]\n",
    "\n",
    "scores = ['precision', 'recall']\n",
    "\n",
    "for score in scores:\n",
    "    print(\"# Tuning hyper-parameters for %s\" % score)\n",
    "    print()\n",
    "\n",
    "    clf = GridSearchCV(SVC(C=1), tuned_parameters, cv=5,\n",
    "                       scoring='%s_macro' % score)\n",
    "    clf.fit(X_trainGrid, y_trainGrid)\n",
    "\n",
    "    print(\"Best parameters set found on development set:\")\n",
    "    print()\n",
    "    print(clf.best_params_)\n",
    "    print()\n",
    "    print(\"Grid scores on development set:\")\n",
    "    print()\n",
    "    means = clf.cv_results_['mean_test_score']\n",
    "    stds = clf.cv_results_['std_test_score']\n",
    "    for mean, std, params in zip(means, stds, clf.cv_results_['params']):\n",
    "        print(\"%0.3f (+/-%0.03f) for %r\"\n",
    "              % (mean, std * 2, params))\n",
    "    print()\n",
    "\n",
    "    print(\"Detailed classification report:\")\n",
    "    print()\n",
    "    print(\"The model is trained on the full development set.\")\n",
    "    print(\"The scores are computed on the full evaluation set.\")\n",
    "    print()\n",
    "    y_true, y_pred = y_testGrid, clf.predict(X_testGrid)\n",
    "    print(classification_report(y_true, y_pred))\n",
    "    print()\n",
    "\n",
    "# Note the problem is too easy: the hyperparameter plateau is too flat and the\n",
    "# output model is the same for precision and recall with ties in quality."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "pickle.dump(X, open( \"X_5gram.p\", \"wb\" ) )\n",
    "pickle.dump(y, open( \"y_5gram.p\", \"wb\" ) )\n"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
